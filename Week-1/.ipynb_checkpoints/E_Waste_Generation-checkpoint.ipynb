{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "87E6n2xlZj8m"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow gradio pillow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import datetime\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"E-Waste Classification Model\")\n",
    "\n",
    "#Step 1: Upload and Unzip Dataset\n",
    "def setup_dataset():\n",
    "    print(\"üìÅ Please upload a ZIP file containing e-waste image folders (by class name)\")\n",
    "    try:\n",
    "        uploaded = files.upload()\n",
    "        if not uploaded:\n",
    "            raise ValueError(\"No file uploaded!\")\n",
    "\n",
    "        zip_path = list(uploaded.keys())[0]\n",
    "        unzip_path = \"/content/ewaste_dataset\"\n",
    "\n",
    "        if os.path.exists(unzip_path):\n",
    "            shutil.rmtree(unzip_path)\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)\n",
    "\n",
    "        contents = os.listdir(unzip_path)\n",
    "        if len(contents) == 1 and os.path.isdir(os.path.join(unzip_path, contents[0])):\n",
    "            nested_path = os.path.join(unzip_path, contents[0])\n",
    "            for item in os.listdir(nested_path):\n",
    "                shutil.move(os.path.join(nested_path, item), os.path.join(unzip_path, item))\n",
    "            os.rmdir(nested_path)\n",
    "\n",
    "        class_folders = [d for d in os.listdir(unzip_path) if os.path.isdir(os.path.join(unzip_path, d))]\n",
    "        if len(class_folders) < 2:\n",
    "            raise ValueError(\"At least 2 class folders are required.\")\n",
    "\n",
    "        total_images = sum([len([f for f in os.listdir(os.path.join(unzip_path, d)) if f.lower().endswith(('jpg', 'jpeg', 'png'))]) for d in class_folders])\n",
    "        if total_images < 10:\n",
    "            raise ValueError(\"Dataset must contain at least 10 images.\")\n",
    "\n",
    "        return unzip_path, class_folders\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error setting up dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "#Step 2: Prepare Dataset\n",
    "def prepare_datasets(unzip_path):\n",
    "    total_images = sum([len([f for f in os.listdir(os.path.join(unzip_path, d))\n",
    "                           if f.lower().endswith(('jpg', 'jpeg', 'png'))])\n",
    "                       for d in os.listdir(unzip_path) if os.path.isdir(os.path.join(unzip_path, d))])\n",
    "\n",
    "    batch_size = min(32, max(4, total_images // 10))\n",
    "    img_height, img_width = 224, 224\n",
    "\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.05),\n",
    "        layers.RandomZoom(0.05),\n",
    "        layers.RandomContrast(0.05)\n",
    "    ])\n",
    "\n",
    "    val_split = 0.2 if total_images > 50 else 0.1\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        unzip_path,\n",
    "        validation_split=val_split,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        unzip_path,\n",
    "        validation_split=val_split,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "    train_ds = train_ds.cache().shuffle(min(1000, total_images)).prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, class_names, num_classes, batch_size, img_height, img_width\n",
    "\n",
    "#Step 3: Build Model\n",
    "def build_model(num_classes, img_height, img_width):\n",
    "    base_model = EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3))\n",
    "    base_model.trainable = True\n",
    "    fine_tune_at = len(base_model.layers) - 30\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base_model(x, training=True)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "        loss_fn = 'binary_crossentropy'\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        loss_fn = 'sparse_categorical_crossentropy'\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.AdamW(learning_rate=5e-5, weight_decay=1e-5),\n",
    "        loss=loss_fn,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---In Progess for better Improvements in Training Machine---\n",
    "\n",
    "#Step 4: Train Model\n",
    "def train_model(model, train_ds, val_ds):\n",
    "    model_dir = f\"/content/model_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    callbacks_list = [\n",
    "        callbacks.ModelCheckpoint(f\"{model_dir}/best_model.h5\", save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "        callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
    "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=4, min_lr=1e-7)\n",
    "    ]\n",
    "\n",
    "    epochs = min(30, max(10, len(list(train_ds)) * 2))\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks_list)\n",
    "    model.save(f\"{model_dir}/final_model\", save_format='tf')\n",
    "    return history, model_dir\n",
    "\n",
    "#Step 5: Plot History\n",
    "def plot_history(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#Step 6: Gradio Interface\n",
    "def create_gradio_interface(model_dir, class_names, num_classes, img_width, img_height):\n",
    "    model = tf.keras.models.load_model(f\"{model_dir}/final_model\")\n",
    "\n",
    "    def predict(image):\n",
    "        if image is None:\n",
    "            return \"Upload an image.\"\n",
    "        img = image.convert(\"RGB\").resize((img_width, img_height))\n",
    "        img_array = tf.keras.utils.img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        predictions = model.predict(img_array, verbose=0)\n",
    "\n",
    "        if num_classes == 2:\n",
    "            score = float(predictions[0][0])\n",
    "            return {\n",
    "                class_names[1]: round(score, 4),\n",
    "                class_names[0]: round(1 - score, 4)\n",
    "            }\n",
    "        else:\n",
    "            probs = tf.nn.softmax(predictions[0]).numpy()\n",
    "            return {class_names[i]: round(float(probs[i]), 4) for i in range(num_classes)}\n",
    "\n",
    "    interface = gr.Interface(\n",
    "        fn=predict,\n",
    "        inputs=gr.Image(type=\"pil\", label=\"Upload Image\"),\n",
    "        outputs=gr.Label(num_top_classes=num_classes),\n",
    "        title=\"E-Waste Classifier\",\n",
    "        description=f\"Upload an e-waste image to classify it among: {', '.join(class_names)}\",\n",
    "        theme=gr.themes.Soft()\n",
    "    )\n",
    "    return interface\n",
    "\n",
    "#Main\n",
    "def main():\n",
    "    unzip_path, class_folders = setup_dataset()\n",
    "    train_ds, val_ds, class_names, num_classes, batch_size, img_height, img_width = prepare_datasets(unzip_path)\n",
    "    model = build_model(num_classes, img_height, img_width)\n",
    "    history, model_dir = train_model(model, train_ds, val_ds)\n",
    "    plot_history(history)\n",
    "    interface = create_gradio_interface(model_dir, class_names, num_classes, img_width, img_height)\n",
    "    interface.launch(share=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGSUGrCwaiMO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBWz-1SQakK2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOSZDegIuCL/d06kWLIkkm4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
